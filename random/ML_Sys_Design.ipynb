{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b600b50-b3ed-4a9a-b20a-8d15b53d7153",
   "metadata": {},
   "source": [
    "# GENERAL NOTES\n",
    "Is ml even needed? What ie the right solution?How much compute do we have? How fast do we need answers? How many users do we serve? How will this change across time? Is there any offline capabilites? What are our ethical responsibilities (data privacy, Biases, etc). Also, keep in mind, you never know parameters, you only know estimations of parameters\n",
    "\n",
    "## When in doubt, ask \"what are we doing this for; what is the objective, and what are the constraints? What are other ways about it?\"\n",
    "\n",
    "## When in doubt, approximate!\n",
    "\n",
    "## When in doubt, say the obvious things! Say all of the obvious things!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b127a-4314-47f3-9015-ecfbeb51f3e0",
   "metadata": {},
   "source": [
    "# ML Sys Design Overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488dfcf9-b537-4ffd-a29f-8af10401053c",
   "metadata": {},
   "source": [
    "## Design Framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac00de8a-d1a2-4e64-8dc0-5b924ab545a4",
   "metadata": {},
   "source": [
    "### Initial Questions\n",
    "- Why do we want to do this? Who will be consuming this and how? What metrics wdo we expect to move?\n",
    "- What is the size of the dataset? What are the latency requirmenets?\n",
    "- What will the inputs and outputs be? What is the high level flow?\n",
    "\n",
    "### High Level Flow\n",
    "#### Rec Sys Example Flow\n",
    "- candidate fetch stage\n",
    "- filters and other business logic\n",
    "- pre-ranking stage\n",
    "- full ranking stage\n",
    "- reranking stage\n",
    "\n",
    "#### Inf Extraction Example Flow\n",
    "- content classification\n",
    "- entity extraction\n",
    "- entity resolution\n",
    "\n",
    "### Data Collection Processing and Storing\n",
    "- What kind of data do we need? How much?\n",
    "- Where does it come from? How expensive is it?\n",
    "- How do we sampel from the data? How do we remove outliers, annotate, and account for collection / labeling biases?\n",
    "\n",
    "### Feature engineering\n",
    "- What features are important, and how do we know?\n",
    "- How can we leverage the features to optimize the model?\n",
    "\n",
    "### Modeling and Evaluation\n",
    "- Evaluating and training different model architectures\n",
    "- Dataset quality and bias issues\n",
    "- Over and underfitting, hyperparameter tuning\n",
    "- how do you balance offline goals (loss function minimization) and online goals (maximizing revenue / user engagement)\n",
    "\n",
    "### Deployment and serving\n",
    "- How much complexity to the system is added by the model?\n",
    "- How do we monitor and maintain the model?\n",
    "- How do we modify models once they are deployed into production?\n",
    "- How do we deal with perpetuating biases in deployed models? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52acebe-6756-4bd8-b14d-59c63ca6de0e",
   "metadata": {},
   "source": [
    "# 1:) Problem Clarification\n",
    "\n",
    "## 1.) Why would we want to recommend content to the user?\n",
    "- Relevance | Discoverability | Increased engagement | Increased revenue | Better Understanding of Customer Behavior\n",
    "- N.b. 80% of Netflix watches come from their recommendations\n",
    "  \n",
    "## 2.) What metrics do we expect to improve?\n",
    "- User retention\n",
    "- Positive and negative engagements, e.g. clicks and reports\n",
    "- User \"state progression\" -> convert light users to medium and heavy users\n",
    "- Subsriptions / follows - increase density of network, benefical all the way around\n",
    "- impressions, costs per engagement, monetizable engagements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667122c3-2d9f-467f-afc4-44690788ae9a",
   "metadata": {},
   "source": [
    "## 3.) What kinds of content should we recommend?\n",
    "- Non personalized content - e.g. trending content, new content, highly rated\n",
    "- Personalized content - in network and out of network\n",
    "- Diverse conent - avoid a filter bubble\n",
    "- Serendipity - random / serendipitous recommendations to keep users engaged / refreshed\n",
    "- Also need to include business considerations - advertiser bids (with potential throttling for burnrate smoothness), boosting, revenuse share, etc.\n",
    "- Ad confliction / repeated advertisements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6e55b-3ed5-4825-8504-c1463120f7e1",
   "metadata": {},
   "source": [
    "## 4.) Blending different content types (e.g. in&out of network, ads)\n",
    "\n",
    "- Interleaving\n",
    "- Heuristics\n",
    "- Separated\n",
    "- Clustered\n",
    "- Global ranking\n",
    "- Reinforcement Learning - develop a frameform for insertion strategy\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8fb6a-4233-4cbf-baf3-5847586b3c71",
   "metadata": {},
   "source": [
    "## 5.) Describe operational parameters of this recommender system\n",
    "\n",
    "- Latency considerations: amount of time for the system to run inference. Typically 100s of ms is the upper limit for real time systems\n",
    "- Throughput: possible processing volume. Typically 100s of requests per second per million users.\n",
    "- Number of candidates: starting point for system, Pinterest has a vatalog of billions\n",
    "- Number of results; output of system, typically one to dozens, depending on the system\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd2481-85ab-4a54-bdbb-8532b46fe79c",
   "metadata": {},
   "source": [
    "# 2:) High Level Design\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897eb66f-dad8-4b88-a072-5cda22de5583",
   "metadata": {},
   "source": [
    "## 6.) Describe the high level design for this recommender system\n",
    "- Candidate generation --> How is this actually done?\n",
    "- Filters - quick assessments\n",
    "- Pre-ranking  / lightweight ranking\n",
    "- heavy ranking / full ranking\n",
    "- reranking )optional) with adtional factors, such as diversity or freshness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af663c3e-0f74-4782-b2c4-c5b2b77ee641",
   "metadata": {},
   "source": [
    "## 7.) How do you surmount the cold start problem?\n",
    "\n",
    "Most recommender systems rely on user-user and user-item engagemetns. Some techniques to bootstrap are:\n",
    "- make them fill out information e.g. demographics, interests\n",
    "- heuristics - take the average of embeddings of similar users, or display non personalized content (trending, diverse, etc)\n",
    "- learning period - increase visibilty of new items / variance, can decay over time\n",
    "- Contextual bandits - systematic approach. Adjust strategy based on feedback to maximimze long term engagement. Upper Confidence Bound balances explore and exploint by recommending itemst aht have the highest upper confidence bound on reward given the available context.\n",
    "\n",
    "Some modeling techniques are:\n",
    "- Fallback models - when there isn'te enough data, provide less acturate features\n",
    "- Collaborative models - interpolate beteween content-forarrd and conventional modeling. This provides a difficulty in complex formulation of objective funciton\n",
    "- hybrid models - combine behaviorual and latent contnet.\n",
    "- Dropout - force the model to apply dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c00d52-5219-4cbb-a74f-991991b3ff5e",
   "metadata": {},
   "source": [
    "# 3:) Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c43b3e-9d44-4f75-a58e-8202e49b1ea3",
   "metadata": {},
   "source": [
    "## 8.) What datasets do we need?\n",
    "\n",
    "- RecSys typically need user-tiem interaction data (clicks purchaces, follows)\n",
    "- Demographic features can be helpful\n",
    "- metadata can be helpful\n",
    "- positive examples (instances where correct answer is known)\n",
    "- negative examples (instances where correct answer is not in teh candidate list, i.e. we may not know what the answer is, but we have some examples of what the answer isn't\n",
    "- Typically user-item interactions are sparce, candidate generators train by way of negative sampling - select small subset of items that are not relevant\n",
    "- preranking - knowledge distillaiton - inputs to the model, along with outputs, the student model is optimized to produce outputs that are similar to the theacher's outputs. Unlike heavy ranking, don't need ground turth labels. More options for collecting data as a result. One appraoch is to pull all input candidates and ask a heavy ranker to score them offline, thus the pre-ranking model can learn what the heavy ranker might like.\n",
    "- Counterfactual reasoning framework: estimate the effect of changing one or more variables ina  system. Estimate how a user would have behaved if a different set of candidates were presented, minimze regret\n",
    "   Traditionally done during A/B experiments, but that can be time and resource intensize. Instead, counteractual reasoning can be employed offline to tackle this. One approach is to allow all generated candidates to survive until heavy ranking and annotate each step where a candidate is scored / filtered out. Mark the candidates ulitimately served. It is possible then ot compute the amount of regret htat each heuristic contriputes. It is not flawless as it only esimates the user engangement, it can help pinpoint frutiful paths. Can be supplemented with A/B tests.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f7028-7462-4a7a-9492-1e1cbcb471a1",
   "metadata": {},
   "source": [
    "## 9.) How do we collect these datasets?\n",
    "\n",
    "- Data must be representative of the users and items, must be large enough to train a model, and must be constructed in a way that minimizes the impact of bias\n",
    "### Candidate generation stage: \n",
    "- negative sampling is used in place of optimizing against all items or only positive items (whichmay result in overprediciton of negative items)\n",
    "- Uniform Sampling - randomly select anything not in the users history as negative samples. Simple, but may not force model to distinguish between positive items and negatives that resemble positives\n",
    "- Popularity based - more popular = more liekly to be positive\n",
    "- Popularity dampened - reduces advantage of very popular items\n",
    "- Faraway negative sampling - select negatives that are very far away from positive items, or with lower scores. May produce uninformative neavies similar to random sampling\n",
    "- Hard Negative Sampling - contemporary approach, selects negatives that are similar to positives. Can be prone to false negatives. PinSange and Monte Carlo Negative Sampling are examples.\n",
    "- GANs - KBGAN, for example - softmax based model as generator to sample negatives likley to confuse the discriminator, margin loss based model for discriminator. Hard to generate many samples.\n",
    "\n",
    "### Light Ranking stage\n",
    "- Biased sampling - Not sure\n",
    "- Uniform sampling - uniformly random sampling. Most diverse sampling, but unable to evaluate ranking metrics\n",
    "- Request-level - sample all input candidates - im not quite sure what this means\n",
    "- In practice some combination is often best; uniform for training, request level for evaluation, or equest can be used to boost diversity, etc.\n",
    "\n",
    "### Heavy Ranking Stage\n",
    "\n",
    "- Stream of data from sandidates served to users. Fed back into model to improve itself over time.\n",
    "- Update frequency - data freshness is important.\n",
    "- Delayed feedback - in many real time systems, interactions are only available fter a (possibly long and random) delay. This will cause naive stratigies which consider any data point a negative example until a positive label becomes avialabe tend ot underpredict these instances.\n",
    "- Negative sampling: Number of positive samples typically much much smaller than the pool of served candidates, leavding to severe class imbalance problems. for example, positive ad impressions may be less than 0.01%. This skews towareds negative examples. Oversampling and downsampling are commonly used methods\n",
    "- Explore/exploit - Needed to aboid biases, as discussed below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25eded-c492-417b-b9b8-e935c070b0d8",
   "metadata": {},
   "source": [
    "## 10.) What sources of biases might be found in the dataset?\n",
    "- Position bias - items at top are more likely to be clicked by user.\n",
    "- Presentation of the item influeneuse the users decision. E.g. if ad happens to be next to attractive images, might get unfair number of clicks\n",
    "- trust bias - users trust the recommneder system too much, don't actually act with own intent\n",
    "- serving bias - algorithimic bias, recommends similar items to those tha have historically performed will. Perpetuation of biases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f628f-0988-412f-89ec-23a485712918",
   "metadata": {},
   "source": [
    "## 11.) How do we mitigate serving bias?\n",
    "- failure to explore candidate space. Explore/exploit is essential to understand in rec sys.\n",
    "- Epsilon-greedy - add some random data to the training set. recommeds the item with a prob of 1-epsilon, while uniformly randomly selecting something oelse with probabiliyt of epsilon. Tends ot ouptperform more advanced methods like bandit approaches.\n",
    "- Contextual bandits. Randomly sample from a posterior distribution\n",
    "  Causual inference - esimate the causeal effects of alternate actions.\n",
    "  learning period - boost new items with a decay based on time. GIves higher weights to newer data and gradually decrease weight over time. does not address other problems like lack of diversity of exploration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b4fbf-998a-4395-b48d-3ee8a929afeb",
   "metadata": {},
   "source": [
    "## 12.) How do we mitigate positional bias\n",
    "- Add randomness to the position of items, e.g. randomly shuffle\n",
    "- add positional features - incorporate it into the training to understand its effect\n",
    "- can model positional bias, use it as a normlaizer or regularizer, butassumes that the relationship is known and can be modeled.\n",
    "- Multi-task model - youtube implements this, at least at one point\n",
    "- Adversarial training - define an auxillary task that predicts the positon of items in teh training. Negate the gradient to comban influence of position. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2c405-9372-4be4-8ccf-b1b50656278b",
   "metadata": {},
   "source": [
    "# 4:) Candidate Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca38c3-163f-4520-a841-422167ebfdf1",
   "metadata": {},
   "source": [
    "## 13.) Where do candidates come from? List Potential Sources\n",
    "\n",
    "### Non-peronalized sources\n",
    "- popular conent\n",
    "- trending content\n",
    "- new conent\n",
    "- trending in contenxtual areas (categories, gerographic locations, topics)\n",
    "\n",
    "### Perosnalized in-network\n",
    "- items generated by users or companies the user is following / connectd to\n",
    "- historical conent - user has previouly consumed, highly rated, etc.\n",
    "\n",
    "### Personalized out of network\n",
    "- Content based filtering - items similar to previously viewed contnet\n",
    "- Collaborative filtering - users own preferences,etc.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2601d5-46e3-4d2e-a948-484355774453",
   "metadata": {},
   "source": [
    "## 14.) What are the benefits and drawbacks of each source?\n",
    "\n",
    "- Non personalized sources - good starting point for new users, good for popular content, but may not be tailerd and might be limited in diversity\n",
    "- Personalized in network - highly relevant and finds new items, but less diverse and not useful for new users\n",
    "- Personalize out of network - highly personalized and tailored, also good for new users, but can require significant user data and processing power to generate recommendations based on similarity or content based filtering. May result in filter bubble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2e33d-233b-4a6a-b72f-f63155de664a",
   "metadata": {},
   "source": [
    "## 15.) Describe how candidate generation works at a high-level\n",
    "\n",
    "- Fetch sources - get sources that can act as seeds for generating candidates, e.g. embeddings. For example, a music streaming service might fetch sources such as user's listening history, songs on the users playlist, and artists they folow.\n",
    "- Generate candidates - use a candidate generation algo - graph based algos, DNNs, etc. (see below.)\n",
    "- Filter candidates - merge and prune to get to a fair number for pre-ranking.\n",
    "- Candidates can be generated from different sources, making this stage many to many. Twiller applies dozens of combos to generate candidates for thier systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ba7a0-83e8-4c33-92cc-e33e2f97e8fe",
   "metadata": {},
   "source": [
    "## 16.) What are some algorithms for generating candidates?\n",
    "\n",
    "### Neighborhood Based Methods:\n",
    "Leverage user preferences between items to generate candidates. Slope One and Pearson R are examples. Slope one is an item-based method that predicts the rating of an item by consdiering the differences in ratings between pairs of items that users have rated. Perarson R is a user based method that computes the corellation coefficent between teh use r and other users to identify similar users and recommend items based on their ratings. These do not learn embeddings.\n",
    "\n",
    "### Graph-based methods:\n",
    "Model the relationships between items or users as a graph and use graph algos to generate candidates. See graph embeddings below for more.\n",
    "\n",
    "### Latent methods\n",
    "Matrix facotirzation and DNNs to generate candidates. Captures latent relationships that are not directly observable in the data. PinSage is a GCN. Aggregates feature information from a suser's one-hop neighborhood. Google uses Two-Tower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e14530-84fd-47e2-967b-f75151919835",
   "metadata": {},
   "source": [
    "## 17.) How might you develop an embedding approach to retrieve canddiates?\n",
    "\n",
    "### Matrix Factorization (MF)\n",
    "- Decombpose rating matrix into low-rank matrices. Common technique is Singular Value Decomposition. Decomposes originla matrix into three separate matrixces, left, right, and singular value. Left matrix is embeddings.  Another is weighted matrix factorization. Optimization techniques such as SGD and Weighted altenrating least squares can be used to optimize the embeddings. Can be difficult to incorporate user and item features. Can capture up to second order features.\n",
    "\n",
    "### Deep Neural Networks\n",
    "Improvement over MF tecniques. Highly nonlinear. Campures complext features more efficently than conventional MF methods. Popular models are sequecne models, graph neural networks, and Two Towers.\n",
    "#### Sequence Models\n",
    "Neural Language models. Can be used to create user and item embeddings. Treats users history as a sequence of words. Neural language model learns embeddings that caputre the sequential dpeendinecies. Leverage attention mechanisms in tranformers to generate embeddigns. Learn more accurate embeddings. Air BNB does this. \n",
    "#### Graph Neural Netowrks\n",
    "Graph Convolutional Networks (example) - network desinged to handle graph structured data. Gather and combine feature informaiton from local neighborhoods of nodes by performing convlutions recursiveely. Stack them to caputre both local and global graph structure. LEverages both content and graph structure to generate usre and item embeddings. PinSage and PinnerSage do this. \n",
    "\n",
    "### The Two Towers\n",
    "AKA SplitNet, or vector product models. Divides a DNN into two sub-networks that process user and item features separately. No crossing features between them. Output is a fixed size vector that represents the user and item embeddings, respectively. SCcore can be computed with different similarity functions, such as inner product or hadamard products. Offers an andvantge in that it allows for independent embedding of new users and items. Useful for whern there is a constant influx of new users and items. \n",
    "\n",
    "### Graph Embeddings:\n",
    "Graph embeddings AKA network embeddings, are a tecnique used to convert nodes into compact low dim representaitons. One example is SimClusters - community based graph embedding approach. \n",
    "\n",
    "Another exmaple is Heterogeneous Information Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d032e2a-a2c7-4ffe-bb5d-5602f97e9bd6",
   "metadata": {},
   "source": [
    "## 18.) At scale, candidate generation cannot score every potential candidate in real-time. What are some ways to solve this?\n",
    "\n",
    "- Use Approximate Nearest Neighbors (ANN) to efficenlty find top candidates. Efficently search high dim spaces by approximating the distnaces betweenpoints. Methods include:\n",
    "  - Locality Sensitive Hasing\n",
    "  - Inersted File Index sith Product Quantization - Compress and quantie data into compact codes\n",
    "  - Hierarchical Navigabele Small WOrld - Construct a graph of high dim items with high clustering coeff - nearby nodes tend to be connected.\n",
    "  - Score offline - precompute and store a list of top candidates for each user or item, can be effective for related-time recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabf64f-e953-4634-8146-0efd4cc6e639",
   "metadata": {},
   "source": [
    "## 19.) How do you index newly created content?\n",
    "\n",
    "- In Matrix Factorization,  just solve the matrix equation (Weighted alternating least squares)\n",
    "- In Two Tower approach - save resulting embedding\n",
    "- Sim clusters - straightforard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5ae5b-c9da-4fa8-9483-175826cd5bbc",
   "metadata": {},
   "source": [
    "## 20.) Suppose we need to limit the number of candidates. How should we merge and prune from differtn algorithms?\n",
    "Several otpions are available:\n",
    "- Heuristics - known performance heursitics, proor knowledge. Might not take into account qaulity of candidates\n",
    "- Thresholding - only let over a scrore through. Does not take into account relative qulaty\n",
    "- Universal scoring - normalze scores, but can create addtional work and might be a misalighmnet of objectives\n",
    "- regression - linear regression, this can cause latency issues.\n",
    "- Light ranking - very fast pre ranker - use more comlex model, again there are downsides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbc8bf-ea78-4ec4-bc75-9bf7e6bff02c",
   "metadata": {},
   "source": [
    "## 21.) Why not use the candidate generator to rank items?\n",
    "\n",
    "- Multiple candidate generators may be used in a system, scores may not be directly comparable.\n",
    "- Ranking task involves considering smaller pool of candidates, lead to more accurate\n",
    "- Scoring function may not be optimized for ranking, i..e ranking and candidate generation are not synonyms. Multiple objectives might be needed for ranking. Allows for separation of objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea0061-7ab5-4188-b853-883dc716c62a",
   "metadata": {},
   "source": [
    "# 5.) Light Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c903fd9-204e-4dd2-b46a-44ad787f4208",
   "metadata": {},
   "source": [
    "## 22.) What is pre-ranking? What does it do?\n",
    "\n",
    "A light ranking model is a simpliefied version of a heavy randking model. Quickly rands candidates, screens for top candidates. Optimizes recall or cumulative gain. Employed when latency of rec sys is critical / important. Typically eliminates 25 to 90 percent of candidates. Allows for the heavy ranker to be more complex. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb1f3d-78fb-466c-8f51-746d2a693ea7",
   "metadata": {},
   "source": [
    "## 23.) What should the pre-ranking model learn?\n",
    "\n",
    "KNOWLEDGE DISTILLATION - a technique used to transfer knowledg from a large, complex model to a msller, simplier model. Train the studen tmodel to mimic th eouptus of hte teacher model. \n",
    "\n",
    "KD involvees using outputs of hte teachrer model as targets for the stduent, minimze the difference between its own outputs and target outputs. Main drawback is that if the teacher model is not well trained the distilled knowlege will be wrong too.\n",
    "\n",
    "Can also learn directly from groutnd truth labels, but this might be a bad idea - getting tground trught may be impractical, training data might be imblanaaced, correlation can be enefical for reducing system error. However can incororpate gorund truth into featuers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4062f8-7a94-43e5-8bc7-49e6ba9d6320",
   "metadata": {},
   "source": [
    "## 24.) What are some evaluation metrics for the model?\n",
    "\n",
    "- Normalized cumulative gain.\n",
    "- top-k recall\n",
    "- expected top-k loss - differnece in gain value for top-k candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b21331-71d2-4e79-b0c0-4d2f00d13398",
   "metadata": {},
   "source": [
    "## 25.) What are some suitable algorithms for this model?\n",
    "\n",
    "- Heuristics - averageing predicted engagements\n",
    "- Lgistic regression, quick to train and update\n",
    "- Two Tower arcitectures - good but misses crossing features\n",
    "- Two Tower to Lightweight DNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb3bbf-d5f8-4283-996d-4d4be42ea906",
   "metadata": {},
   "source": [
    "## 26.) Suppose we need to pre-rank a large number of candidates. How do we optimize the model for this?\n",
    "\n",
    "Cached or precompute embeddings\n",
    "Parallelism, adjust atch size\n",
    "Densify input features / compress them\n",
    "cache at multiple levels to minimize feature hydration\n",
    "opmitize architecture - reduce size and complexity- apply sqeezing\n",
    "Compving two tower with above concetps\n",
    "Cace pairwise model scores, precomute all offline. Can incur storage costs. Not a good idea if data distributions shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e46d4-e703-4fe1-8c1c-6dbbf65f7e35",
   "metadata": {},
   "source": [
    "# 6.) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af86d7-53ea-4820-8326-537a52254223",
   "metadata": {},
   "source": [
    "\n",
    "## 27.) What features should we use? What are their intuitions?\n",
    "\n",
    "### Target Features\n",
    "Describe the user\n",
    "- demographics\n",
    "- relevant keywords\n",
    "- User's interests\n",
    "- Request-level features (spefici page of the the user interface, origiginating query, device, client, carrier, network condition, geogrpahic location, time of daty, day of week, etc.\n",
    "- How much content they consume\n",
    "- Embedding features - users' engagement history, embeddings of subsribers, etc.\n",
    "- revenue (ad) models - average bid depth, bid value, click through rate, fill rate, network valuation\n",
    "\n",
    "### Candidate Features\n",
    "- Static attributes - ID, category, etc\n",
    "- numeric features, history, recent engagements\n",
    "- content's author, advertiser, ad campaighn\n",
    "- metadata - type of ad product, bit type, currency\n",
    "  \n",
    "### Crossing features\n",
    "How much content has by this author has the user consumed? \n",
    "When was the last time they consumed it?\n",
    "Explicti corssing - use din logistic regression\n",
    "Embedding crossing - crossing the embeddings\n",
    "Deep crossings (deep and cross network rom google)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980863c2-8414-4548-afe6-fbf0da8377d2",
   "metadata": {},
   "source": [
    "## 28.) How do we handle textual or id-based features?\n",
    "- Low cardinality, can use one-hot encoding. Rule of thumb, what less than 20% of the dataset size or squar root fo the dataset size for cardinality. \n",
    "- high cardinality - hashing - reduce the dimensionality of the input vector.\n",
    "- Embeddings - repsresent categorical features as contionous valued vectors in lower dim space. However, may over generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d0909-b426-4848-b11c-64a75acec963",
   "metadata": {},
   "source": [
    "## 29.) What about counting features? What are problems with using counting features?\n",
    "Couting features can get large. Good idea to normalize in some way. \n",
    "- Log transforms - log plus 1, good idea but doesnt handle negative values\n",
    "- z-score scaling (quantile distributions) can be computationally expensive\n",
    "- Bucketing - binning / discretizing, quantile bountds. Clipping - cut off above and below thresholds, good for outliers.\n",
    "- MLP directly and using the oupt as input to remaining layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5870b3-a556-4468-990c-394ef905a2bd",
   "metadata": {},
   "source": [
    "# 7.) Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347c0fd-bdf7-4bcf-a32a-a65fb5f86e1d",
   "metadata": {},
   "source": [
    "## 30.) What should the heavy ranking model learn?\n",
    "\n",
    "Learning to Rank is the process of training the ranking model using data.\n",
    "- Pointwise - predict a single relevance score or each candidate. Sigmoid cross entropy loss is pospular. Disadvanctage of not capuring relationships\n",
    "- Pairwise - distingiish between preferred and non-preffered candidates. Compare 2 candidates at a time and predict which one would be user preffered. Some times oupterforms pointwise models\n",
    "- Listwise - take into account entire list. Probabilist loss function that optimizes KL divergence between predicted ranking and ideal ranking. ListMLE maximizes the probaility of the ideal ranking. Downside is significant amount of training data and comp. resourrces are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5e24a-f9e9-4515-93ef-74b20dcfb2fe",
   "metadata": {},
   "source": [
    "## 31.) What are some reasonable modeling algorithms?\n",
    "- Logistic regression. Can be updated through contionus learning\n",
    "- Gradient boosting - XGBoost trees, caputre non linaer feature interacitons nadhandle missing values.\n",
    "- Hybrid - Start with a tree, feed into linear classifier. \n",
    "DNNsProcess vast amounts of data without perfomance saturation, can be fit to specific problem domains. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d3997-420d-4085-b7e2-d50f0e7cced5",
   "metadata": {},
   "source": [
    "## 32.) Describe what your model architecture might look like.\n",
    "- Logistic regression\n",
    "- - DNNs - improve genearalization capability by learning low dim dense embedding, but struggles to learn reprsentation sin spare interactions\n",
    "  - Google introduced Wdie and Deep. Pointrise ranking models\n",
    "    , leading to hybrid models\n",
    "- More recelntly have been using multi ltask learning approaches. Optimize both clicks and likes.\n",
    "- Attention / transformer based models have emerged as powerful approaches\n",
    "- Attention mechanisms have three elements:key, query, and value\n",
    "- key is an input element (current user interaction)\n",
    "- query is an element we want to focus on)\n",
    "- vaue is information we want to extract for the query element\n",
    "- Compute simlairty score, using dot product. Passes to softmax, indicaing releance of query. Sum up weighted value, passed to feedforward network.\n",
    "- Multiheaded attention, multipe sets of all of these.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fc9db-570f-489c-bc05-047594d72bfa",
   "metadata": {},
   "source": [
    "## 33.) What if the model predictions need to be calibrated?\n",
    "\n",
    "- ad platforms might charge advertisers for the number off times their ads are dispalyed. As such, there might be a mismath between the billing method use by the ad platform and the avertisers objectives. Leads to situations where an advertiser is paying for impressions that do not lead to the desired conversion event.\n",
    "- Essential to have calibrated predictions.\n",
    "Guarantees provided by cross entropy loss are limited to data distributions\n",
    "\n",
    "Calibration layer may be applied - Platt scaling or isotonic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cabcd8-33c8-4b5b-a5c7-2d4eb48802e1",
   "metadata": {},
   "source": [
    "## 34.) What are some appropriate evaluation metrics and why?\n",
    "### Pointwise Metrics\n",
    "- Area under the precion recall curve\n",
    "- Average and sqaured error\n",
    "- Relative Cross entropy\n",
    "\n",
    "### Ranking metrics\n",
    "- normoalized discounted cumulative gain - normlaized by a reference score\n",
    "- Recall at K - measures proportion of relevant titmes that are recommended\n",
    "- Mean average precision - average precison of recommeded items\n",
    "- Mean recipriocal rank. Evaluate ability of model to rank rleevant items hgiher than irrelevant items\n",
    "- ordered pair accuracy measures the proporiton of correctly ordered candidate pairs\n",
    "\n",
    "\n",
    "### Infrastructure metrics\n",
    "- Latency\n",
    "- Success rate\n",
    "- COmputational Cost\n",
    "### Product Metrics\n",
    "- positive engagemetns\n",
    "- Negative egngagements\n",
    "- Retetntion\n",
    "- Revenue\n",
    "- Conversion rate\n",
    "- Advertiser cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9121fec-c6f6-4112-899f-957c9427186a",
   "metadata": {},
   "source": [
    "## 35.) How do you balance multiple objectives, e.g. Likes vs. Subscribes?\n",
    "\n",
    "0 train a multi task model. One example is mulit-gate mixture of experts architetcutre. Bottom layer schared across all experts. \n",
    "Train separate models \n",
    "learn from weighted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b655f8-c3ff-44f9-ad4f-e55e3ab9c774",
   "metadata": {},
   "source": [
    "## 36.) Should we build one multi-task model or combine multiple smaller models?\n",
    "\n",
    "multi task moels can share knolege\n",
    "separate models can more easily see per-objective perormance\n",
    "MTM can see relationships between objectivs\n",
    "Flexibitlty separate models wins\n",
    "Complexity - all depends\n",
    "Reduncdancy - multi task models\n",
    "Deployment - single models easier to deply serve and maintain\n",
    "resource constraints - all depends\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212342c-ea57-4168-878e-14b401ce0b74",
   "metadata": {},
   "source": [
    "# 8.) Deployment & Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091804d6-09a5-4214-8cc9-6bf610e103f9",
   "metadata": {},
   "source": [
    "## 37.) How do you enable the model to serve real time requests?\n",
    "- Loading models\n",
    "- Serving model requests\n",
    "- Switching between different versions of the modle (hotswapping)\n",
    "- management interface\n",
    "- Hydrate and cace features and predicitons, convert features to appropriate foramt, handle request batching and fialures, and scribe requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1fb210-97f7-4615-aa61-1310674afaa1",
   "metadata": {},
   "source": [
    "## 38.) What can we cache in the serving system and where?\n",
    "\n",
    "-  cache top k items for each user\n",
    "-  - cache embeddings - low dim vectors that represent users and items\n",
    "   - cache features - more likely to be reused between calls, can be cached at mutliple levels\n",
    "   - cache prediction scores. Avoid need to recalculate, reduces server load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6752085-2a18-4bed-b2b4-3c03a879d8b4",
   "metadata": {},
   "source": [
    "## 39.) How often do we update the model?\n",
    "DEPENDS. Answer below to understand:\n",
    "- Concept drift - if model relies heavily on id based features or keyword based features, might neeed to be updated more frequenlcy\n",
    "- covariate drift - as input data changes, might need to change model\n",
    "- lable drift changes to the target variable\n",
    "- system drift changes in candidate generation or other upstream, need to retrain model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c099280-faf0-4a29-871f-8ea3e847eec9",
   "metadata": {},
   "source": [
    "## 40.) How does online experimentation (A/B) testing work?\n",
    "\n",
    "- User-binned - users are assigned to two or more groups, groups are compared\n",
    "- cluster binned - requests are randomly assigned, clusters are compared. Allows for improved moniotirn, including factors such as latencly.\n",
    "- BEWARE INTERFERENCE -  some ways to mitigate this:\n",
    " - sequential experimentaltion - dont run concurrently\n",
    " - merge exepriments\n",
    " - mutual exclusion - orthogonality\n",
    " - multivariate testing. but challenging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a67f0f-9c0d-4fe3-a758-8895b49077e9",
   "metadata": {},
   "source": [
    "## 41.) How should the server support model experimentation? \n",
    "\n",
    "- load from a repo where various versions are stored\n",
    "- rolling deployment, restart the server with the models to be tested\n",
    "- hotswapping - model snapshots can be swapped in and out of production without need for full restart. May need more sophisticated config setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614004c1-70ba-4f52-b060-68badcf584c4",
   "metadata": {},
   "source": [
    "## 42.) Describe some ideas for model experiments\n",
    "\n",
    "Objective - ranking models cna be trainied to optimize different objectives - multi task, compositte, transform\n",
    "Features - experiemnt with different features\n",
    "Preprocessing\n",
    "Algorithims\n",
    "Model architetcture\n",
    "Training Dataset\n",
    "Retraining\n",
    "Loss functions\n",
    "Activation functions\n",
    "regularization methods\n",
    "hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573959f-14ff-42e1-9702-1299f44d5d33",
   "metadata": {},
   "source": [
    "## 43.) How would you go about predicting which offline evaluation metric improves online metrics? \n",
    "\n",
    "- Run A/B testing and measure correlation\n",
    "- Select something like PR AUC, nDCG, or Ordered pair Accuracy, for example. modify the rec system. Observe effect.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a821d4-17d2-4ae0-bb64-f50325f22d40",
   "metadata": {},
   "source": [
    "## 44.) How do you debug if online experiment performance drops over time?\n",
    "\n",
    "- Ensure metrics are statistically significant\n",
    "- Veryify experiment's healht\n",
    "- Verify data\n",
    "- Look for changes in recent deployments\n",
    "- Check for interference from other experiments\n",
    "- Check secondary metrics\n",
    "- Changes in user behavior - could explain issues\n",
    "- World events (no one wants to watch videos about vaccines after covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f41e5-3c63-47a1-81be-0beccc7cb8b9",
   "metadata": {},
   "source": [
    "# ML DESIGN 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f189793-f1e8-4678-8e4a-66aaa1b0daab",
   "metadata": {},
   "source": [
    "Information retrieval two stage approach: candidate generation and ranking. Here are examples:\n",
    "- search problems - find relevant results for a query\n",
    "- finding similar entities - similar to collaborative filtering approaches\n",
    "- Identifying near duplicates - similar to content based filtering approaches\n",
    "- entity resolution - maps different representations of an entity to a common taxonomy  -  can cast the problem a s a search problem\n",
    "- Question answering - answe an NL question by retreving relevant information from a large corpus of documents. Traditionally:\n",
    "- - Query decomp - reformat querty into smaller units\n",
    "  - hypothesis generation - geenrate a set of candidate answers\n",
    "  - Evidence retrieval - retrieve and rank evidence\n",
    "  - synthesis - generate a coherent and NL answer to the question - needs additional processing such as NL generation\n",
    "  - answer ranking - rank baseed on relevancy, etc. Similar to heavy ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c178da0-3aa1-445f-a918-0b7c36893ccc",
   "metadata": {},
   "source": [
    "More design questions:\n",
    "- Classification - supervised learning where goal is to predict a categorical label\n",
    "- regression - predict a continuous numerical value for a given input\n",
    "- information extraction - subfield of NLP that involves automatically extracting structred informaiton from unstructed text data.\n",
    "  clustering - unsupervised learning where you group similar items in a dataset. Doesn't involve predicting a label, instead the algorthm tries to find natural groupings.\n",
    "  generative modeling - create new data that is similar to the training data. More recently NLG has become popular (e.g. Chat GPT)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78256133-ec52-4d90-b395-877dca903c45",
   "metadata": {},
   "source": [
    "# 1:) High-Level Design\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53b0c7-1f14-4621-83f3-8e7b94b59f41",
   "metadata": {},
   "source": [
    "## 1.) Develop a ML system to extract info from financial reports\n",
    "\n",
    "Think of systems as many component boxes\n",
    "\n",
    "ALEXA:\n",
    "\n",
    "text to speech <-- information extraction / named entity recognition  <-- intent classification <-- automatic speech recognition\n",
    "more components, more problems\n",
    "\n",
    "web crawler to get documents --> classifer to check --> ocr to read reports --> translator to get english --> infomration extraction --> entity resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc1bdf5-a5d3-4a23-980f-d1a46f3c9977",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.) Design a ML system that can gauge the positivity or negativity of a given text\n",
    "\n",
    "Sentiment analysis challenges:\n",
    "- negation: I did not like this\n",
    "- sarcasm: the weather is nice for a penguin\n",
    "- comparisons: this move is better than the book, but the book sucks\n",
    "- inversions: the phone is pretty, but thats it\n",
    "- negatives that are positive \"lebron is a bad man!\"\n",
    "\n",
    "Solutions:\n",
    "- rule based NLP. easy to implmeent but time consuming and hard to generalize\n",
    "- lexicon based - fast but hard to generlaize. Weight words, add up the scores\n",
    "- non neural models - support vecotr machines etc. Can identify sentiment without rules, generlizes well but stil hard to ge tsarcasm, needs alot of labeled data\n",
    "- Neural Netowrks - context and relationships, LSTMs and transfomer encoders\n",
    "- RoBERTa is good. applies masking. Can be computationally expensive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810f462-29ec-453e-9eb6-79a8210a62e9",
   "metadata": {},
   "source": [
    "## 3.) Build a ML system that can identify the prevalence of topics within a news article\n",
    "\n",
    "- word based: use word embeddings, fast but doesn't captuer relationships. Could extract key word, then embed words, then find similiarity, report most similar words.\n",
    "- matrix factorization: Latent Semantic Analysis. Non-negative Matrix Factorization.\n",
    "- probalistic topic modeling: use bayesian inference, assume each document is generated by a set of topic probabiliteis from a dirichlet distribution, then a set of words is drawn from the topics. Then infer the most likely topic distribution for each document of a number of iterations. Hirarchical version is an extension that allows for an unbounded number of topics to be interred. \n",
    "- neural topic models: Vareational autoencoders. map to latent space, etc. \n",
    "\n",
    "- Vareational autoencoder - words are converted to embeddings, feed forward, reparameteriztion, softmax. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841753b-b02f-4072-bf31-329ead914e11",
   "metadata": {},
   "source": [
    "## 4.) Design a ML system that condenses a body of text into a single paragraph\n",
    "\n",
    "Two main approaches: extractive and abstractive\n",
    "- Extractive: select important sentences and arrange them in coherent summary. Readibilty can be a problem.\n",
    "- - feature extraction\n",
    "  - sentence selection\n",
    "  - reduncandy removal\n",
    "  - sentence ordering\n",
    "  - coreference resolution\n",
    "  - summary\n",
    "- Abstractive\n",
    "  - encoder-decoder networks trained on large datasets\n",
    "  - transformers are vetter versions of this. large capaicty. mixture of latent concepts with great precsion\n",
    "  - can generate coherent and conscise by generating new sentences\n",
    "  - relies on generating new sentences, can hallucinate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c292f2-4c82-435c-85f5-497e37020fb9",
   "metadata": {},
   "source": [
    "## 5.) Design a ML system that understands commands like \"Play the top songs byt he beatles\"\n",
    "\n",
    "Needs:\n",
    "- Natural Language Understanding\n",
    "- Intent classification - understaing what hte user wants. \"play music\". Use a model to classify intput to predefined output. Rule based system. \n",
    "- information extraction - extract relevant informaiton. \"top songs\" artist = \"beatles\" . Apply named entity recognition techniques\n",
    "- entity resolution - maps the extracted entites to a specific reepresentation of the system. we need to understand that top songs refers to teh most listed songs and map the beatles to an atrist. Can use a knowledge graph and a mustic api library. \n",
    "- Recenly, LLMs smash this up. They can perform intent classification and information extraction in a single step through fine tuning approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ed995-ac43-479c-9497-7ae6b5f663b4",
   "metadata": {},
   "source": [
    "# 2:) Data Collection\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b87f3-f113-4a35-9935-45206d2c2197",
   "metadata": {},
   "source": [
    "## old.) How do you collect data and prepare a dataset for training/\n",
    "-- see above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb96684-6ca0-458b-aee7-774d5b2e16e3",
   "metadata": {},
   "source": [
    "## 6.) (SUPERVISED) What are some challenges when it comes to collecting labels?\n",
    "Two common types:\n",
    "- Logged labels - clicks, transactions, or other interactions. Can be subject to biases - positional or presentation bias. Labels may not accuractly reflect true preferences.\n",
    "- Human annotated labels - less prone to some bias, but mislabeling is a problem. due ot errors, misunderstanding, or misalignment of incentives (e.g. mechanical turk)\n",
    "\n",
    "Ways to improve human labeling are:\n",
    "- clear inscturions\n",
    "- screening\n",
    "- tracking (use golden data - pre labeled benchmark data)\n",
    "- voting (use mulitple respondse)\n",
    "- validation - expert validator\n",
    "- captchas - veryif annotatoer is paying attention\n",
    "- pattern checking (statiscial analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3695d0a3-18a3-47c7-b7eb-da34eb23deaf",
   "metadata": {},
   "source": [
    "## 7.) (UNSUPERVISED) How do you prepare data for clustering algorithms?\n",
    "\n",
    "- Does not require data labels, but need to preprocess data well\n",
    "\n",
    "### Categorical Features\n",
    "- Do not natively accept categorical features (but some do, like deep embedding clusters)\n",
    "- One hot encoding! But can lead to a high dimensional feature space\n",
    "- label encoding - assign integer to each featuere\n",
    "- ordinal encoding - can lead to issues if there is no actual order\n",
    "\n",
    "\n",
    "### Numerical Features\n",
    "- log transforms\n",
    "- Z score scaling (normalization)\n",
    "- bucketing (i.e. quantile transforms\n",
    "- missing features:\n",
    "  - remove samples\n",
    "  - remove feature\n",
    "  - impute missing feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24607217-a779-43a8-8baa-26631bfe19cc",
   "metadata": {},
   "source": [
    "# 3:) Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68afd8-5aaa-4a4f-ad9d-cef971bf737d",
   "metadata": {},
   "source": [
    "## 8.) How do you perform feature engineering for supervised classification or regression?\n",
    "\n",
    "- in rec sys, features might be demographics, interests, or past behaviors\n",
    "- for detecting bot traffic, IP addresses, time structure, temporal patterns\n",
    "- in NLP, features may be n-grams, stems, lemmas, word embeddings, etc\n",
    "- in CV, features are raw pixel values,\n",
    "- can be static or dynamic\n",
    "\n",
    "Contextual features:\n",
    "- in NLP, contextual features might refer to teh surrounding text of a document\n",
    "- in Rec Sys, might inluide info about the origination request\n",
    "- in pricing models, might include nearby listings, number of videws, etc\n",
    "\n",
    "Sequential features:\n",
    "- historical data\n",
    "- past interactions\n",
    "- in NLP, text is inherently sequential\n",
    "\n",
    "Crossing features; interaction based crossing features - users x authors / advertisers\n",
    "Engineering cross is when features are combined\n",
    "can embed featers (DeepFM)\n",
    "\n",
    "Derived features:\n",
    "derived from using existing features. One example is binarization - for exampe (isUpper, IsAcronym, etc\n",
    "windoed/ decayed mechanisms can be helpful. Radios can be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0458e-5b92-421a-887b-8c238eb008ba",
   "metadata": {},
   "source": [
    "## 9.) What are featueres used by generative models?\n",
    "Generally just take the raw data as input, undergoes some transformation.\n",
    "- tokenized text aas in put in LMs\n",
    "- Machine translation - sentence pairs\n",
    "- OCR - vast collection of scanned images\n",
    ", need ground routh. Skew normalizntion, etc\n",
    "- in speech rcogniztion, Mel Frequency Cepstral Coefficeints, derived from filter banks. Filter banks are used to decompose audio signal into frequency components, while MFCCs are obtained by applying additional transofrmation on top of the filter bank outputs.\n",
    "- in Text to Speech systems, use raw text as input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceca3f1-ef2d-4380-bb4a-7a2039fb5c7c",
   "metadata": {},
   "source": [
    "# 4:) Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f28020-1815-4cc0-a3c7-470edfaa52c8",
   "metadata": {},
   "source": [
    "## 10.) Build a model that performs Information Extraction (i.e. from financial reports)\n",
    "\n",
    "- Rule based systems, handcrafted by domain experts\n",
    "- Rule based hybrid approaches\n",
    "- Statistical models - named entity recognition, hidden marvkov models, etc.\n",
    "- - Hidden markov models model the probabiilty of a sequence of tages given a sequence of input tokens using joint probability\n",
    "  - Maximum Entropy Markove Models are extenions that allow for conditional modeling\n",
    "  - Conditional Random Fields are extensions to MEMMs that solve label bias problems,\n",
    "- Neural Models: CNNs, BiLSTM\n",
    "- - CNNs - used for IE by convulting the text using a slideing window, eg. 3 otkens, to extract hte most relevant features, fed to a fully connected layer\n",
    "  - Bidrirectional LSTM:\n",
    "- Popular option is BiLSTM-CNN-CRF - combines all three fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37991c1e-8a16-4e02-9648-978edf59603b",
   "metadata": {},
   "source": [
    "## 11.) What are some evaluation metrics for information extraction?\n",
    "\n",
    "- Precision - proportion of instances where predicted model is correct\n",
    "- Recall - proportion of instances that are correct\n",
    "- F1 score.\n",
    "- Can also use accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c677e85-21c4-4876-9133-a50ecf00a7f3",
   "metadata": {},
   "source": [
    "## 12.) Build a model that performs classification (e.g. sentifment analysis)\n",
    "\n",
    "- rule ased models: quick but not complex\n",
    "- logistic regression. Estimates probability of events based on values\n",
    "- Gradient boosting\n",
    "- Deep Neural Networks\n",
    "\n",
    "- Factorization machines enable feature crossings, which can help caputre complex interactions.\n",
    "- Atteniton-based mechanisms, such as transfomer encoders, enable for long term depencendy captures.\n",
    "- Convvolutions are used for processing spactial data. Useful for image classificaiton, graph rep. and caputing speech signals.\n",
    "- SVMs not super popular anymore because they don't do as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9551428-7ad6-458d-be9e-c5f0adcd2607",
   "metadata": {},
   "source": [
    "## old.) How do you evaulate a classifier model? \n",
    "precision, recall, confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4349c-b811-455d-8aed-5e1ef56a107e",
   "metadata": {},
   "source": [
    "## 13.) Build a model that performs regression (e.g. demand forecasting)\n",
    "\n",
    "- linear regression. Good starting point.\n",
    "- Polynomial regression. Also fine.\n",
    "- Support Vector Regression. Commonly use d in pricing.\n",
    "- Tree based approaches. Random Forest Regression; bagging approach that trains each DT on random subsets of the data. BTregression is a boosting approach that trains DTs sequentially\n",
    "- DNNs - gained immense popularity; caputres higehr oder interactions\n",
    "- Factorization machines can also be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97ee52-35ec-4a7f-bea2-008de2a568c5",
   "metadata": {},
   "source": [
    "## old.) How do you evaluate quality of a regression model?\n",
    "\n",
    "MAE, RMSE, MSE, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351162fc-e4a3-4138-bab8-8a07ad10a20d",
   "metadata": {},
   "source": [
    "## 14.) What are some techniques for matching identified topics with a taxonomy?\n",
    "\n",
    "- Top-down approach; use a set of proor words or phrases that are known to be relevant\n",
    "\n",
    "- Supervissed LDA\n",
    "\n",
    "- Labeled LDA\n",
    "\n",
    "- Bottom-up approach - topics are first identified through topic modeling, then extracted\n",
    "\n",
    "- human in the loop - involve human experts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5d976-7cb9-492a-b2ff-bf26f0584968",
   "metadata": {},
   "source": [
    "## 15.) How do you evaluate the performance of a topic modeling algorithm?\n",
    "\n",
    "- Not universally agreed upon.\n",
    "- Perplexity - log-likelihood of a test set\n",
    "- Topic coherence\n",
    "- Topic diversity\n",
    "- downstream performance\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf53008-3de9-4481-8711-c9f44cf718cb",
   "metadata": {},
   "source": [
    "## 16.) Build a model to perform clustering (e.g. group similar news articles)\n",
    "Document clustering aims to group similar documents together based on content. \n",
    "\n",
    "### Document Representation:\n",
    "- Earliest methods used bag-of-words; each docuemnt represented as a vector of wood frequencies\n",
    "- - this fails to capture the semantic menaing of words\n",
    "  - To address this, Term Frequncy Inverse Docuemnt Frequncy was intorduced. FT-IDF takes into account hte importance of each word itn eh document across the corpus, resulting in etter clustering performance\n",
    "- Word embeddings, such as Word2Vec and GloVe, became popular. Word embeddings encode words into dense continous vectors; capturing the sematntic meaning of words.\n",
    "- After word embedding, they can be fed into a RNN or LSTM, which can caputre sequential dependenceis. The final state can be used as a fixed length represnetation of the document\n",
    "- Attention based / transformer models are popular now, caputre long range dependenceis. BERT can handle otu of vocabulary words through subweord tokenization. ThuS BERT represents OOV word as a combination of wubword units\n",
    "\n",
    "\n",
    "### Cluster Assignment\n",
    "- k-means was earliest, but is limited in isensitivity to initiazliation, and inability to handle non-spehrical clusters\n",
    "- hierarchial clutering introducted; groups recurivsly in tree-like strucres\n",
    "- Density based clustering; identifes clusters based on regions of high density in the data space.\n",
    "- Gaussian Mxiture Modelsare are probablistic models that aim to find a mixture of multiple Gaussian distributisons that best fit a given dataset.\n",
    "- Deep Embedding Clustering casts the problem in the form of an autoencoder., uses K-means and KL-divergence loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f88f8-1afc-4031-8127-886cd5acb3f2",
   "metadata": {},
   "source": [
    "## 17.) What are metrics for evaluating the performace of clustering algorithms?\n",
    "\n",
    "### Unsupervised Clustering Accuracy\n",
    "- Widely used equivalent of classification accuracy. Measures percentage of documentst aht are correctly assigned.\n",
    "- Adjusted Mutual Information. takes into account chance clusterings\n",
    "- Adjusted Rand Index - similarity between two clusterings - considers all pairs and tallies the ones assigned to the same lcuster.\n",
    "- AMI and ARI are best used depending on the distribution of data (balanced vs unbalanced)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a69481-fe27-4553-a80a-90124c981e1e",
   "metadata": {},
   "source": [
    "## 18.) Build a model that can generate text (e.g. to summarize a document)\n",
    "\n",
    "- Noisy Channl  appraoches, inspired by Statisical Machine Translation\n",
    "- Abstractive summarization is better now.\n",
    "- RNNs are used for this\n",
    "- LSTMs are better than RNNs by incorporating memory cells, which have gates\n",
    "- CNNs were less frequenctly used, but have some adanated s t- they generate fixed size contexutal representaitons while RNNs store informaiton fromt eh entire past. CNNs thus have pore precise control over range dependenceis.\n",
    "- LLMs now do this best\n",
    "- Transfomers:\n",
    "    - T5 (Text To Text Transfmore Transformer) - pre training\n",
    "    - BART (bidrectional and autoregressiv etransformer, from FAIR. Denosing autoencoder\n",
    "    - PEGASUS. Random selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd9a01-2aa6-49f4-bdae-cfe60690c59d",
   "metadata": {},
   "source": [
    "## 19.) What are some metrics used for assesing quality in generative tasks\n",
    "\n",
    "Evaluation metrics for generative tasks typically have an objective of measuring similarity between machine-generated text and reference text.\n",
    "### Co-occurence-based\n",
    "text summarization primarily uses ROUGE (recall-oriented-understudy for gisting evaluation). ROUGE mesuares the overlap between the generated summary and the reference summary in terms of n-gram co-occurance. \n",
    "Machine translation uses BLEU score, typically. \n",
    "### Edit distance-based\n",
    "ASR systems are evaulated using Word Error Rate. WER mesurees difference between machine generated scrpit and reference script\n",
    "OCR systems evaluate word accuracy and character accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1174d88-bbcd-4573-b8f5-843a70302248",
   "metadata": {},
   "source": [
    "# 5:) Deployment & Serving\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5d51b-5f08-4fc8-a31b-6da073715152",
   "metadata": {},
   "source": [
    "## 20.) What are steps to prepare a model to serve predictions?\n",
    "\n",
    "- Data preparation, analysis, and transformation. understand pattersn / relationships that could be leveraged to develop the model\n",
    "- training tuning and evaluating\n",
    "- deploying to production - model blessing step - model is validated on a predefined stet of critereia\n",
    "- upload to model repository\n",
    "- infrastructure check\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f843c69-9ba3-4e41-b6f7-86ff3c938a8a",
   "metadata": {},
   "source": [
    "## old.) How do you enable the model to serve real-time requests?\n",
    "-- see above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24d71a-10aa-4a54-9ad5-ccac1f44b581",
   "metadata": {},
   "source": [
    "## 21.) How do you make offline predictions, such as inferring topics from a collection of text?\n",
    "COntext - offline prodiction - ML models in batch scoring jobs for a large number of data points, not requried in real time.\n",
    "- eamil and push notifications,\n",
    "- building datasets that feed into other systems\n",
    "- Data analysis - sentiment analysis\n",
    "- demand and prcie models\n",
    "Approach: unlike online prediciton, batch predition involves the coillection of data in a data warehouse or cloud storage, then process\n",
    "- cloud storage, suhc as GCS\n",
    "- data processing pipeline can be used\n",
    "- batch prediction job can ber used\n",
    "- Use Hadoop Map Reduce\n",
    "- write back to cloud storage in CSV or parquet.\n",
    "- Export to data warehouse or other palce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6c551-2dfa-4549-ace9-301bc1bc1c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1723dc6f-1156-44c4-ba1f-60d214b08d2b",
   "metadata": {},
   "source": [
    "Techniques for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfacd98b-7ec1-4022-b8b6-2cbe5f2f2f1c",
   "metadata": {},
   "source": [
    "## CI/CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8041bd-746c-4637-be2d-fdb5e65433c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP, information retrieval, knowledge graphs, and knowledge graph embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4e2b8-4379-4f94-af8c-185f49cac6c9",
   "metadata": {},
   "source": [
    "# Why Grid Search for Hyperparameter Tuning is Often Not Ideal\n",
    "\n",
    "> **It is generally better *not* to tune hyperparameters strictly on a grid.**\n",
    "\n",
    "### Key Reasons:\n",
    "\n",
    "- **Grid search is inefficient in high dimensions.**  \n",
    "  - If you grid-search 3 values per hyperparameter and have 5 hyperparameters, you need \\(3^5 = 243\\) evaluations.\n",
    "  - Most of those evaluations are wasted because only a few hyperparameters matter a lot.\n",
    "  - Grid search spends time trying many combinations that don't help.\n",
    "\n",
    "- **Hyperparameter importance is uneven.**  \n",
    "  - Some hyperparameters (like learning rate) are extremely sensitive.\n",
    "  - Others (like batch size) are less sensitive.\n",
    "  - A grid treats all hyperparameters as equally important, which is wrong.\n",
    "\n",
    "- **Random search and smarter methods are more efficient.**  \n",
    "  - **Random search** often finds better hyperparameters faster by covering the space better.\n",
    "  - **Bayesian optimization** intelligently models which areas are promising and focuses search there.\n",
    "  - Methods like **Hyperband** and **Successive Halving** can early-stop bad candidates to save time.\n",
    "\n",
    "### Quick Interview Summary:\n",
    "\n",
    "- Grid search **scales badly** (exponentially) with more hyperparameters.\n",
    "- **Random search** is usually better.\n",
    "- **Bayesian and adaptive methods** (e.g., Hyperband) are even better in many cases.\n",
    "\n",
    "### Bonus Tip:\n",
    "\n",
    "> Grid search is still acceptable when:\n",
    "> - There are very few hyperparameters (e.g., 1–2).\n",
    "> - You have a **large** compute budget.\n",
    "> - You use a **coarse-to-fine** search strategy: start coarse, refine promising areas with random or adaptive search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6023ba4-1f12-43dc-aa38-5fc37fb8b50b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
